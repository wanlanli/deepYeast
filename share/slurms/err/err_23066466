[I 2022-12-27 10:03:52.955 ServerApp] jupyterlab | extension was successfully linked.
[I 2022-12-27 10:03:52.962 ServerApp] nbclassic | extension was successfully linked.
[I 2022-12-27 10:03:58.076 ServerApp] notebook_shim | extension was successfully linked.
[I 2022-12-27 10:03:58.221 ServerApp] notebook_shim | extension was successfully loaded.
[I 2022-12-27 10:03:58.222 LabApp] JupyterLab extension loaded from /work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/python3.9/site-packages/jupyterlab
[I 2022-12-27 10:03:58.222 LabApp] JupyterLab application directory is /work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/share/jupyter/lab
[I 2022-12-27 10:03:58.226 ServerApp] jupyterlab | extension was successfully loaded.
[I 2022-12-27 10:03:58.289 ServerApp] nbclassic | extension was successfully loaded.
[I 2022-12-27 10:03:58.289 ServerApp] Serving notebooks from local directory: /work/FAC/FBM/DMF/smartin/cellfusion/wanlan
[I 2022-12-27 10:03:58.289 ServerApp] Jupyter Server 1.18.1 is running at:
[I 2022-12-27 10:03:58.289 ServerApp] http://dnagpu003:8880/lab?token=922a80790adfc8424ac1e311547239ac9572d45d28e809de
[I 2022-12-27 10:03:58.289 ServerApp]  or http://127.0.0.1:8880/lab?token=922a80790adfc8424ac1e311547239ac9572d45d28e809de
[I 2022-12-27 10:03:58.289 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 2022-12-27 10:03:58.372 ServerApp] 
    
    To access the server, open this file in a browser:
        file:///users/wli6/.local/share/jupyter/runtime/jpserver-473640-open.html
    Or copy and paste one of these URLs:
        http://dnagpu003:8880/lab?token=922a80790adfc8424ac1e311547239ac9572d45d28e809de
     or http://127.0.0.1:8880/lab?token=922a80790adfc8424ac1e311547239ac9572d45d28e809de
[W 2022-12-27 10:05:29.979 LabApp] Could not determine jupyterlab build status without nodejs
[I 2022-12-27 10:05:35.959 ServerApp] Kernel started: 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
2022-12-27 10:05:42.004620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 10:05:46.229070: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-12-27 10:05:58.705665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 10:05:58.705802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 10:05:58.705809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-12-27 10:06:20.326815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 10:06:23.254295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
2022-12-27 10:07:14.289668: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
2022-12-27 10:07:21.252027: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-27 10:07:21.419082: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
[I 2022-12-27 10:07:35.302 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:09:35.497 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:11:35.674 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:13:35.793 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
2022-12-27 10:13:46.764641: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ../model_dir/checkpoint: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?
[I 2022-12-27 10:15:35.850 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:17:35.985 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:19:36.059 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:27:33.159 ServerApp] Kernel restarted: 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
[W 2022-12-27 10:27:33.168 ServerApp] Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x7f07a4292ac0>
[W 2022-12-27 10:27:33.220 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[I 2022-12-27 10:27:36.154 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[W 2022-12-27 10:27:37.717 ServerApp] Nudge: attempt 10 on kernel 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
[W 2022-12-27 10:27:42.727 ServerApp] Nudge: attempt 20 on kernel 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
2022-12-27 10:27:52.182963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 10:27:53.396962: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-12-27 10:28:03.893803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 10:28:03.893924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 10:28:03.893930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-12-27 10:28:26.026421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 10:28:27.216196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
[I 2022-12-27 10:29:36.241 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:31:36.544 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
2022-12-27 10:31:37.900932: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
2022-12-27 10:31:44.811419: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-27 10:31:45.071328: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
[I 2022-12-27 10:33:36.631 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
2022-12-27 10:34:29.675678: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ../model_dir/ckpt-60000.data-00000-of-00001: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?
[I 2022-12-27 10:35:36.756 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:37:36.868 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:39:37.047 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:41:37.219 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[W 2022-12-27 10:43:01.918 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[W 2022-12-27 10:43:01.919 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[I 2022-12-27 10:43:37.346 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:47:37.619 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 10:49:37.870 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:17:42.250 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:19:42.589 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:21:42.827 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:23:42.899 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:25:43.029 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:27:43.120 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[W 2022-12-27 11:29:42.123 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[W 2022-12-27 11:29:42.124 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[W 2022-12-27 11:29:43.057 ServerApp] iopub messages resumed
[W 2022-12-27 11:29:43.057 ServerApp] iopub messages resumed
[I 2022-12-27 11:29:43.215 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:29:46.069 ServerApp] Kernel restarted: 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
[W 2022-12-27 11:29:46.075 ServerApp] Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x7f07a42926a0>
[W 2022-12-27 11:29:47.565 ServerApp] IOPub message rate exceeded.
    The Jupyter server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--ServerApp.iopub_msg_rate_limit`.
    
    Current values:
    ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    ServerApp.rate_limit_window=3.0 (secs)
    
[W 2022-12-27 11:29:50.588 ServerApp] Nudge: attempt 10 on kernel 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
[W 2022-12-27 11:29:55.596 ServerApp] Nudge: attempt 20 on kernel 7af7f43b-3bd6-41e8-bc03-c9dc9d980cc7
2022-12-27 11:30:01.331984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 11:30:01.529023: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-12-27 11:30:09.760212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 11:30:09.760362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-27 11:30:09.760369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[I 2022-12-27 11:31:43.481 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
2022-12-27 11:33:04.515734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-27 11:33:05.057392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
2022-12-27 11:33:30.266329: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
2022-12-27 11:33:38.304693: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-27 11:33:38.638518: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
[I 2022-12-27 11:33:43.793 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:35:44.071 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
[I 2022-12-27 11:37:44.575 ServerApp] Saving file at /project/deepyeast/test_main.ipynb
slurmstepd: error: *** JOB 23066466 ON dnagpu003 CANCELLED AT 2022-12-28T06:03:43 DUE TO TIME LIMIT ***
