2022-12-22 23:57:55.921283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-22 23:57:56.084891: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-12-22 23:58:02.938202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-22 23:58:02.939159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib64:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen/gcc-8.4.1/gcc-10.4.0-7fjdev7tbifqfonsjwlqmr6qcnza2ezu/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/mpfr-4.1.0-4owr5jskgrebkppacvwkfa7tdtlqjalg/lib:/dcsrsoft/spack/arolle/v1.0/spack/opt/spack/linux-rhel8-zen2/gcc-10.4.0/gmp-6.2.1-rg3gv5myy7lt46cjxvmdmsghhyhxguqo/lib:/work/FAC/FBM/DMF/smartin/cellfusion/wanlan/miniconda3/envs/tf210/lib/
2022-12-22 23:58:02.939173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-12-22 23:58:15.982561: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-22 23:58:19.542672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0
2022-12-22 23:58:19.545201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38224 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:e2:00.0, compute capability: 8.0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I1222 23:58:20.074479 140359792264832 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I1222 23:58:20.081989 140359792264832 deeplab.py:58] Synchronized Batchnorm is used.
I1222 23:58:20.082716 140359792264832 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 6, 3, 3], 'backbone_layer_multiplier': 4.5, 'width_multiplier': 1, 'stem_width_multiplier': 1, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'wider_resnet', 'use_axial_beyond_stride': 16, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 4, 'drop_path_keep_prob': 0.8, 'drop_path_beyond_stride': 4, 'drop_path_schedule': 'linear', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': 0, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': True, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 2, 'value_expansion': 4, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.99, epsilon=0.001), 'conv_kernel_weight_decay': 0.0}
I1222 23:58:20.627249 140359792264832 deeplab.py:99] Setting pooling size to (33, 33)
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.912450 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.916063 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.917935 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.918514 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.920842 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.921400 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.922885 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.923437 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.925749 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.926293 140359792264832 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I1222 23:58:25.941451 140359792264832 controller.py:391] restoring or initializing model...
I1222 23:58:26.098611 140359792264832 controller.py:395] restored model from ../model_dir/ckpt-1000.
I1222 23:58:26.098753 140359792264832 controller.py:217] restored from checkpoint: ../model_dir/ckpt-1000
I1222 23:58:26.098954 140359792264832 controller.py:236] train | step:   1000 | training until step 10000...
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:27.812002 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:27.858549 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:27.872680 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:28.936356 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:28.951382 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:28.965843 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:29.095704 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:29.110373 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:29.124638 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
I1222 23:58:29.226694 140359792264832 cross_device_ops.py:897] batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1
2022-12-23 00:08:34.790807: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
2022-12-23 00:08:35.028833: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401
2022-12-23 00:08:44.373084: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-12-23 00:08:45.439180: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
W1223 00:21:54.768639 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 1000, expected updated value to be 1100, but it was 1200.
I1223 00:21:54.797989 140359792264832 controller.py:457] train | step:   1200 | steps/sec:    0.1 | output: 
    {'learning_rate': 0.0006684912,
     'losses/train_center_loss': 10.779248,
     'losses/train_regression_loss': 19.6391,
     'losses/train_semantic_loss': 15.501603,
     'losses/train_total_loss': 45.919952}
W1223 00:34:40.585942 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 1200, expected updated value to be 1300, but it was 1400.
I1223 00:34:40.589536 140359792264832 controller.py:457] train | step:   1400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0006548018,
     'losses/train_center_loss': 10.08419,
     'losses/train_regression_loss': 18.136517,
     'losses/train_semantic_loss': 15.428346,
     'losses/train_total_loss': 43.64905}
W1223 00:47:22.431725 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 1400, expected updated value to be 1500, but it was 1600.
I1223 00:47:22.438108 140359792264832 controller.py:457] train | step:   1600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0006410806,
     'losses/train_center_loss': 9.22147,
     'losses/train_regression_loss': 15.661747,
     'losses/train_semantic_loss': 15.243787,
     'losses/train_total_loss': 40.127007}
W1223 01:00:05.458932 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 1600, expected updated value to be 1700, but it was 1800.
I1223 01:00:05.461131 140359792264832 controller.py:457] train | step:   1800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0006273266,
     'losses/train_center_loss': 8.061719,
     'losses/train_regression_loss': 13.7374325,
     'losses/train_semantic_loss': 15.129019,
     'losses/train_total_loss': 36.92817}
W1223 01:12:49.066085 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 1800, expected updated value to be 1900, but it was 2000.
I1223 01:12:49.068403 140359792264832 controller.py:457] train | step:   2000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0006135391,
     'losses/train_center_loss': 6.858917,
     'losses/train_regression_loss': 11.346206,
     'losses/train_semantic_loss': 14.791623,
     'losses/train_total_loss': 32.99675}
I1223 01:12:58.316373 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-2000.
W1223 01:25:40.452579 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 2000, expected updated value to be 2100, but it was 2200.
I1223 01:25:40.462960 140359792264832 controller.py:457] train | step:   2200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.000599717,
     'losses/train_center_loss': 5.7630067,
     'losses/train_regression_loss': 9.526645,
     'losses/train_semantic_loss': 14.234762,
     'losses/train_total_loss': 29.524416}
W1223 01:38:21.783621 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 2200, expected updated value to be 2300, but it was 2400.
I1223 01:38:21.784471 140359792264832 controller.py:457] train | step:   2400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0005858595,
     'losses/train_center_loss': 4.749329,
     'losses/train_regression_loss': 8.042981,
     'losses/train_semantic_loss': 13.171091,
     'losses/train_total_loss': 25.963398}
W1223 01:51:05.586088 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 2400, expected updated value to be 2500, but it was 2600.
I1223 01:51:05.587156 140359792264832 controller.py:457] train | step:   2600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0005719655,
     'losses/train_center_loss': 4.2094784,
     'losses/train_regression_loss': 7.3234277,
     'losses/train_semantic_loss': 11.871513,
     'losses/train_total_loss': 23.404425}
W1223 02:03:46.021812 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 2600, expected updated value to be 2700, but it was 2800.
I1223 02:03:46.022645 140359792264832 controller.py:457] train | step:   2800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0005580338,
     'losses/train_center_loss': 3.5698936,
     'losses/train_regression_loss': 6.4249783,
     'losses/train_semantic_loss': 10.72849,
     'losses/train_total_loss': 20.723364}
W1223 02:16:32.393822 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 2800, expected updated value to be 2900, but it was 3000.
I1223 02:16:32.394825 140359792264832 controller.py:457] train | step:   3000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0005440634,
     'losses/train_center_loss': 3.28953,
     'losses/train_regression_loss': 6.0521045,
     'losses/train_semantic_loss': 9.850381,
     'losses/train_total_loss': 19.192015}
I1223 02:16:40.801609 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-3000.
W1223 02:29:26.164637 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 3000, expected updated value to be 3100, but it was 3200.
I1223 02:29:26.165448 140359792264832 controller.py:457] train | step:   3200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.000530053,
     'losses/train_center_loss': 3.007699,
     'losses/train_regression_loss': 5.705282,
     'losses/train_semantic_loss': 8.87929,
     'losses/train_total_loss': 17.592268}
W1223 02:42:14.668846 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 3200, expected updated value to be 3300, but it was 3400.
I1223 02:42:14.669680 140359792264832 controller.py:457] train | step:   3400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00051600125,
     'losses/train_center_loss': 2.7150805,
     'losses/train_regression_loss': 5.4949083,
     'losses/train_semantic_loss': 8.545018,
     'losses/train_total_loss': 16.755007}
W1223 02:54:54.265924 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 3400, expected updated value to be 3500, but it was 3600.
I1223 02:54:54.266916 140359792264832 controller.py:457] train | step:   3600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00050190696,
     'losses/train_center_loss': 2.304987,
     'losses/train_regression_loss': 4.6508656,
     'losses/train_semantic_loss': 7.8386173,
     'losses/train_total_loss': 14.794474}
W1223 03:07:29.779249 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 3600, expected updated value to be 3700, but it was 3800.
I1223 03:07:29.780084 140359792264832 controller.py:457] train | step:   3800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00048776856,
     'losses/train_center_loss': 1.9405841,
     'losses/train_regression_loss': 4.218002,
     'losses/train_semantic_loss': 7.261343,
     'losses/train_total_loss': 13.419927}
W1223 03:20:14.591716 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 3800, expected updated value to be 3900, but it was 4000.
I1223 03:20:14.592562 140359792264832 controller.py:457] train | step:   4000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00047358443,
     'losses/train_center_loss': 1.7059304,
     'losses/train_regression_loss': 4.079417,
     'losses/train_semantic_loss': 6.794812,
     'losses/train_total_loss': 12.580158}
I1223 03:20:23.094530 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-4000.
W1223 03:33:05.262369 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 4000, expected updated value to be 4100, but it was 4200.
I1223 03:33:05.263379 140359792264832 controller.py:457] train | step:   4200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00045935292,
     'losses/train_center_loss': 1.4870291,
     'losses/train_regression_loss': 3.6177466,
     'losses/train_semantic_loss': 6.242114,
     'losses/train_total_loss': 11.3468895}
W1223 03:45:45.863764 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 4200, expected updated value to be 4300, but it was 4400.
I1223 03:45:45.864617 140359792264832 controller.py:457] train | step:   4400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00044507222,
     'losses/train_center_loss': 1.3267047,
     'losses/train_regression_loss': 3.4610908,
     'losses/train_semantic_loss': 5.7569695,
     'losses/train_total_loss': 10.544766}
W1223 03:58:26.122902 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 4400, expected updated value to be 4500, but it was 4600.
I1223 03:58:26.123757 140359792264832 controller.py:457] train | step:   4600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00043074042,
     'losses/train_center_loss': 1.3131115,
     'losses/train_regression_loss': 3.4970472,
     'losses/train_semantic_loss': 5.7610183,
     'losses/train_total_loss': 10.571177}
W1223 04:11:05.668675 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 4600, expected updated value to be 4700, but it was 4800.
I1223 04:11:05.669510 140359792264832 controller.py:457] train | step:   4800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00041635547,
     'losses/train_center_loss': 1.204066,
     'losses/train_regression_loss': 3.3493261,
     'losses/train_semantic_loss': 5.5376697,
     'losses/train_total_loss': 10.091062}
W1223 04:23:41.735701 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 4800, expected updated value to be 4900, but it was 5000.
I1223 04:23:41.736577 140359792264832 controller.py:457] train | step:   5000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00040191508,
     'losses/train_center_loss': 1.0989057,
     'losses/train_regression_loss': 3.1294465,
     'losses/train_semantic_loss': 5.023001,
     'losses/train_total_loss': 9.251353}
I1223 04:23:49.980024 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-5000.
W1223 04:36:29.153387 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 5000, expected updated value to be 5100, but it was 5200.
I1223 04:36:29.154353 140359792264832 controller.py:457] train | step:   5200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00038741675,
     'losses/train_center_loss': 1.1453986,
     'losses/train_regression_loss': 3.1338665,
     'losses/train_semantic_loss': 4.954686,
     'losses/train_total_loss': 9.233952}
W1223 04:49:09.237492 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 5200, expected updated value to be 5300, but it was 5400.
I1223 04:49:09.238322 140359792264832 controller.py:457] train | step:   5400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00037285784,
     'losses/train_center_loss': 1.0461916,
     'losses/train_regression_loss': 3.0495672,
     'losses/train_semantic_loss': 4.91604,
     'losses/train_total_loss': 9.011799}
W1223 05:01:44.927366 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 5400, expected updated value to be 5500, but it was 5600.
I1223 05:01:44.928189 140359792264832 controller.py:457] train | step:   5600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00035823556,
     'losses/train_center_loss': 0.925157,
     'losses/train_regression_loss': 2.8700452,
     'losses/train_semantic_loss': 4.680075,
     'losses/train_total_loss': 8.475278}
W1223 05:14:28.831304 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 5600, expected updated value to be 5700, but it was 5800.
I1223 05:14:28.849091 140359792264832 controller.py:457] train | step:   5800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0003435466,
     'losses/train_center_loss': 0.8214946,
     'losses/train_regression_loss': 2.8171813,
     'losses/train_semantic_loss': 4.431043,
     'losses/train_total_loss': 8.069718}
W1223 05:27:04.602981 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 5800, expected updated value to be 5900, but it was 6000.
I1223 05:27:04.603838 140359792264832 controller.py:457] train | step:   6000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00032878746,
     'losses/train_center_loss': 0.8250043,
     'losses/train_regression_loss': 2.7196898,
     'losses/train_semantic_loss': 4.3137336,
     'losses/train_total_loss': 7.858427}
I1223 05:27:12.751567 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-6000.
W1223 05:39:51.267234 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 6000, expected updated value to be 6100, but it was 6200.
I1223 05:39:51.268203 140359792264832 controller.py:457] train | step:   6200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00031395437,
     'losses/train_center_loss': 0.9478438,
     'losses/train_regression_loss': 2.9382906,
     'losses/train_semantic_loss': 4.610763,
     'losses/train_total_loss': 8.496899}
W1223 05:52:22.150354 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 6200, expected updated value to be 6300, but it was 6400.
I1223 05:52:22.151197 140359792264832 controller.py:457] train | step:   6400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00029904293,
     'losses/train_center_loss': 1.0234468,
     'losses/train_regression_loss': 3.1008227,
     'losses/train_semantic_loss': 4.712023,
     'losses/train_total_loss': 8.836291}
W1223 06:05:04.296827 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 6400, expected updated value to be 6500, but it was 6600.
I1223 06:05:04.297655 140359792264832 controller.py:457] train | step:   6600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00028404835,
     'losses/train_center_loss': 0.81423587,
     'losses/train_regression_loss': 2.7516406,
     'losses/train_semantic_loss': 4.2405,
     'losses/train_total_loss': 7.8063765}
W1223 06:17:45.359095 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 6600, expected updated value to be 6700, but it was 6800.
I1223 06:17:45.359919 140359792264832 controller.py:457] train | step:   6800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0002689653,
     'losses/train_center_loss': 0.72713304,
     'losses/train_regression_loss': 2.5432944,
     'losses/train_semantic_loss': 3.9527662,
     'losses/train_total_loss': 7.223193}
W1223 06:30:25.759512 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 6800, expected updated value to be 6900, but it was 7000.
I1223 06:30:25.760353 140359792264832 controller.py:457] train | step:   7000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0002537876,
     'losses/train_center_loss': 0.700813,
     'losses/train_regression_loss': 2.4557354,
     'losses/train_semantic_loss': 3.8548853,
     'losses/train_total_loss': 7.0114336}
I1223 06:30:34.251846 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-7000.
W1223 06:43:19.203627 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 7000, expected updated value to be 7100, but it was 7200.
I1223 06:43:19.204596 140359792264832 controller.py:457] train | step:   7200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00023850829,
     'losses/train_center_loss': 0.61411786,
     'losses/train_regression_loss': 2.4032705,
     'losses/train_semantic_loss': 3.799574,
     'losses/train_total_loss': 6.8169622}
W1223 06:56:09.190109 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 7200, expected updated value to be 7300, but it was 7400.
I1223 06:56:09.190961 140359792264832 controller.py:457] train | step:   7400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00022311936,
     'losses/train_center_loss': 0.60246223,
     'losses/train_regression_loss': 2.3729532,
     'losses/train_semantic_loss': 3.7098653,
     'losses/train_total_loss': 6.685281}
W1223 07:08:55.224460 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 7400, expected updated value to be 7500, but it was 7600.
I1223 07:08:55.225287 140359792264832 controller.py:457] train | step:   7600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00020761152,
     'losses/train_center_loss': 0.5586868,
     'losses/train_regression_loss': 2.3016236,
     'losses/train_semantic_loss': 3.5732145,
     'losses/train_total_loss': 6.433524}
W1223 07:21:42.154072 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 7600, expected updated value to be 7700, but it was 7800.
I1223 07:21:42.154920 140359792264832 controller.py:457] train | step:   7800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00019197368,
     'losses/train_center_loss': 0.6041945,
     'losses/train_regression_loss': 2.3697493,
     'losses/train_semantic_loss': 3.6294925,
     'losses/train_total_loss': 6.6034365}
W1223 07:34:32.020851 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 7800, expected updated value to be 7900, but it was 8000.
I1223 07:34:32.021680 140359792264832 controller.py:457] train | step:   8000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00017619283,
     'losses/train_center_loss': 0.83833116,
     'losses/train_regression_loss': 2.8224661,
     'losses/train_semantic_loss': 4.324467,
     'losses/train_total_loss': 7.985264}
I1223 07:34:39.418507 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-8000.
W1223 07:47:24.971791 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 8000, expected updated value to be 8100, but it was 8200.
I1223 07:47:24.972634 140359792264832 controller.py:457] train | step:   8200 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00016025316,
     'losses/train_center_loss': 0.66045517,
     'losses/train_regression_loss': 2.4799356,
     'losses/train_semantic_loss': 3.729077,
     'losses/train_total_loss': 6.869469}
W1223 08:00:01.290192 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 8200, expected updated value to be 8300, but it was 8400.
I1223 08:00:01.291210 140359792264832 controller.py:457] train | step:   8400 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00014413496,
     'losses/train_center_loss': 0.5897579,
     'losses/train_regression_loss': 2.312863,
     'losses/train_semantic_loss': 3.514037,
     'losses/train_total_loss': 6.416658}
W1223 08:12:43.164338 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 8400, expected updated value to be 8500, but it was 8600.
I1223 08:12:43.165206 140359792264832 controller.py:457] train | step:   8600 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00012781343,
     'losses/train_center_loss': 0.57131785,
     'losses/train_regression_loss': 2.2545745,
     'losses/train_semantic_loss': 3.4375525,
     'losses/train_total_loss': 6.2634454}
W1223 08:25:26.548765 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 8600, expected updated value to be 8700, but it was 8800.
I1223 08:25:26.549607 140359792264832 controller.py:457] train | step:   8800 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.00011125627,
     'losses/train_center_loss': 0.5857342,
     'losses/train_regression_loss': 2.2543542,
     'losses/train_semantic_loss': 3.3951569,
     'losses/train_total_loss': 6.235245}
W1223 08:38:08.944098 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 8800, expected updated value to be 8900, but it was 9000.
I1223 08:38:08.944942 140359792264832 controller.py:457] train | step:   9000 | steps/sec:    0.3 | output: 
    {'learning_rate': 9.441945e-05,
     'losses/train_center_loss': 0.51958936,
     'losses/train_regression_loss': 2.1714597,
     'losses/train_semantic_loss': 3.3416672,
     'losses/train_total_loss': 6.032715}
I1223 08:38:17.069299 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-9000.
W1223 08:51:01.420816 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 9000, expected updated value to be 9100, but it was 9200.
I1223 08:51:01.421678 140359792264832 controller.py:457] train | step:   9200 | steps/sec:    0.3 | output: 
    {'learning_rate': 7.723998e-05,
     'losses/train_center_loss': 0.5020043,
     'losses/train_regression_loss': 2.125518,
     'losses/train_semantic_loss': 3.210058,
     'losses/train_total_loss': 5.8375807}
W1223 09:03:43.666605 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 9200, expected updated value to be 9300, but it was 9400.
I1223 09:03:43.667459 140359792264832 controller.py:457] train | step:   9400 | steps/sec:    0.3 | output: 
    {'learning_rate': 5.9620757e-05,
     'losses/train_center_loss': 0.54294443,
     'losses/train_regression_loss': 2.159953,
     'losses/train_semantic_loss': 3.316438,
     'losses/train_total_loss': 6.0193357}
W1223 09:16:28.207617 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 9400, expected updated value to be 9500, but it was 9600.
I1223 09:16:28.208631 140359792264832 controller.py:457] train | step:   9600 | steps/sec:    0.3 | output: 
    {'learning_rate': 4.1391908e-05,
     'losses/train_center_loss': 0.4966428,
     'losses/train_regression_loss': 2.169047,
     'losses/train_semantic_loss': 3.2456887,
     'losses/train_total_loss': 5.9113793}
W1223 09:29:07.851419 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 9600, expected updated value to be 9700, but it was 9800.
I1223 09:29:07.852272 140359792264832 controller.py:457] train | step:   9800 | steps/sec:    0.3 | output: 
    {'learning_rate': 2.2181348e-05,
     'losses/train_center_loss': 0.44299605,
     'losses/train_regression_loss': 2.0220563,
     'losses/train_semantic_loss': 3.152044,
     'losses/train_total_loss': 5.6170964}
W1223 09:41:50.820765 140359792264832 controller.py:448] `trainer.train(100)` did not update `global_step` by 100. Old value was 9800, expected updated value to be 9900, but it was 10000.
I1223 09:41:50.821610 140359792264832 controller.py:457] train | step:  10000 | steps/sec:    0.3 | output: 
    {'learning_rate': 0.0,
     'losses/train_center_loss': 0.45434424,
     'losses/train_regression_loss': 2.0023434,
     'losses/train_semantic_loss': 3.053894,
     'losses/train_total_loss': 5.510581}
I1223 09:41:58.756285 140359792264832 controller.py:486] saved checkpoint to ../model_dir/ckpt-10000.
